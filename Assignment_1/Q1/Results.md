# Parameters


* gamma = 0.999
* epsilon = 1e-6

Here gamma is the discount factor in MDP, the value is not converging for a very long time for gamma = 1 so the above value is chosen, and epsilon is the tolerance for convergence


# Value Iterations:
value(Hostel) = 2041.9216

value(Academic_Building) = 2044.0076

value(Canteen) = 2042.8197

**Optimal Policy:**

π(Hostel) = Class

π(Academic_Building) = Class

π(Canteen) = Class

# Policy Iterations:
value(Hostel) = 2041.9216

value(Academic_Building) = 2044.0076

value(Canteen) = 2042.8197

**Optimal Policy:**
π(Hostel) = Class

π(Academic_Building) = Class

π(Canteen) = Class